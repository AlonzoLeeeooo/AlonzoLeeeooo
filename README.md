### Hi there ğŸ‘‹
![github stats](https://github-readme-stats.vercel.app/api?username=AlonzoLeeeooo&show_icons=true)

ğŸ§‘ğŸ»â€ğŸ“ I am currently a PhD student at the University of Science and Technology of China (USTC). 

ğŸ” My research direction involves a wide series of applications based on generative models such as GANs, Transformers, and diffusion models. For now, I am mainly interested in these tasks: *image inpainting*, *text-to-image generation*, and *video generation*.

ğŸ“‚ To record up-to-date resources of the aforementioned research directions, I have maintained some GitHub repos, including:
- [<u>1. Text-to-Image Generation</u>](https://github.com/AlonzoLeeeooo/awesome-text-to-image-studies): A collection of resources for the Text-to-Image (T2I) Generation task.
- [<u>2. Video Generation</u>](https://github.com/AlonzoLeeeooo/awesome-video-generation): A collection of resources for the Video Generation task.
- [<u>3. Image Inpainting</u>](https://github.com/AlonzoLeeeooo/awesome-image-inpainting-studies): A collection of resources for the Image Inpainting task.
- [<u>4. Radiology Report Generation</u>](https://github.com/AlonzoLeeeooo/awesome-radiology-report-generation): A collection of resources for the Radiology Report Generation (RRG) task.

<p align="center">
    <a href="https://star-history.com/#alonzoleeeooo/awesome-image-inpainting-studies&alonzoleeeooo/awesome-video-generation&alonzoleeeooo/awesome-text-to-image-studies&Date" target="_blank">
        <img width="550" src="https://api.star-history.com/svg?repos=alonzoleeeooo/awesome-image-inpainting-studies,alonzoleeeooo/awesome-video-generation,alonzoleeeooo/awesome-text-to-image-studies,alonzoleeeooo/awesome-radiology-report-generation&type=Date" alt="Star History Chart">
    </a>
<p>

ğŸ§ª I have re-produced/re-implemented some works, which are open-sourced for potential usage by the community:
- [<u>1. Shape-Guided ControlNet</u>](https://github.com/AlonzoLeeeooo/shape-guided-controlnet): A re-implementation of ControlNet trained with shape masks.
- [<u>2. Shape-Guided ControlNeXt</u>](https://github.com/AlonzoLeeeooo/ControlNeXt-svd-shape): A re-implementation of ControlNeXt trained with shape masks.

> [!NOTE]
> These codebases are experimental and would not be guaranteed to be well-performing. If you have any questions about them, please feel free to <u>propose an issue or PR</u>.

ğŸ¤ I am looking for long-term collaboration in ground-breaking projects in computer vision, please feel free to contact me if you are interested. 

ğŸ“œ You can find more information about me in the following websites.
- Google Scholar: https://scholar.google.com/citations?user=Y3NKd1wAAAAJ&hl=zh-CN&authuser=2
- Zhihu: https://www.zhihu.com/people/liu-chang-82-34-78 ï¼ˆ@å«æˆ‘Alonzoå°±å¥½äº†ï¼‰
- ğŸ ï¼ˆå°çº¢ä¹¦ï¼‰ï¼šhttps://www.xiaohongshu.com/user/profile/632dbaa10000000023026ad9?xsec_token=&xsec_source=pc_searchï¼ˆ@å«æˆ‘Alonzoå°±å¥½äº†ï¼‰

ğŸ”¥ Recent News:
- [Nov. 19th] We have released our latest paper titled ["StableV2V: Stablizing Shape Consistency in Video-to-Video Editing"](https://arxiv.org/abs/2411.11045), with the correponding [code](https://github.com/AlonzoLeeeooo/StableV2V), [model weights](https://huggingface.co/AlonzoLeeeooo/StableV2V), and [a testing benchmark `DAVIS-Edit`](https://huggingface.co/datasets/AlonzoLeeeooo/DAVIS-Edit) open-sourced. Feel free to check them out from the links!
- [Sep. 27th] I have open-sourced a re-implementation of ControlNeXt trained with shape masks, where you can find more details in the [GitHub](https://github.com/AlonzoLeeeooo/ControlNeXt-svd-shape) and [Hugging Face repo](https://huggingface.co/AlonzoLeeeooo/ControlNeXt-svd-shape).
- [Sep. 18th] I have open-sourced a re-implementation of ControlNet trained with shape masks, where you can find more details in the [GitHub](https://github.com/AlonzoLeeeooo/shape-guided-controlnet) and [Hugging Face repo](https://huggingface.co/AlonzoLeeeooo/shape-guided-controlnet).
- [Jun. 13th] [Code](https://github.com/AlonzoLeeeooo/LCDG) and pre-trained model weights ([Huggingface](https://huggingface.co/AlonzoLeeeooo/LaCon) and [ModelScope](https://modelscope.cn/models/AlonzoLeeeoooo/LaCon)) of our paper titled ["LaCon: Late-Constraint Diffusion for Steerable Guided Image Synthesis"](https://arxiv.org/pdf/2305.11520) are updated!
- [May 17th] Our paper titled ["Towards Interactive Image Inpainting via Robust Sketch Refinement"](https://ieeexplore.ieee.org/document/10533842) is accepted by TMM 2024! 


![Visitor Count](https://profile-counter.glitch.me/alonzoleeeooo/count.svg)
